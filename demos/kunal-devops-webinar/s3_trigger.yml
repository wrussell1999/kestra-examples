id: data_process
namespace: company.team

variables:
  bucket: s3-trigger-example

tasks:
  - id: log_trigger
    type: io.kestra.plugin.core.log.Log
    message: "{{ read(trigger.objects[0].uri) }}"

  - id: process_data
    type: io.kestra.plugin.scripts.python.Commands
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
    containerImage: ghcr.io/kestra-io/kestrapy:latest
    namespaceFiles:
      enabled: true
    inputFiles:
      input.csv: "{{ read(trigger.objects[0].uri) }}"
    outputFiles:
      - data.csv
    commands:
      - python process_data.py
    
  - id: send_alert
    type: io.kestra.plugin.notifications.slack.SlackIncomingWebhook
    url: "{{ secret('SLACK_WEBHOOK') }}"
    payload: |
      {
        "text": "Data has been processed. View the output here: http://localhost:8086/ui/executions/{{ flow.namespace }}/{{ flow.id }}/{{ execution.id }}/outputs"
      }

triggers:
  - id: watch
    type: io.kestra.plugin.aws.s3.Trigger
    interval: "PT1S"
    accessKeyId: "{{ secret('AWS_ACCESS_KEY_ID') }}"
    secretKeyId: "{{ secret('AWS_SECRET_KEY_ID') }}"
    region: "eu-west-2"
    bucket: "{{ vars.bucket }}"
    action: DELETE
    filter: FILES
    maxKeys: 1
