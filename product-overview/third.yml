id: parallel_data
namespace: company.team

inputs:
  - id: bucket
    type: STRING
    defaults: kestra-example

  - id: region
    type: STRING
    defaults: us-east-1

tasks:
  - id: wdir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: git
        type: io.kestra.plugin.git.Clone
        url: https://github.com/kestra-io/terraform-deployments
        branch: main

      - id: tf
        type: io.kestra.plugin.terraform.cli.TerraformCLI
        inputFiles:
          backend.tf: |
            terraform {
              backend "s3" {
                region = "{{ inputs.region }}"
                bucket = "{{ inputs.bucket }}"
                key    = "terraform.tfstate"
              }
            }
        commands:
          - mv aws-batch/* .
          - terraform init
          - terraform apply -auto-approve
          - terraform output > output.txt
        env:
          TF_VAR_region: "{{ inputs.region }}"
          TF_VAR_bucket: "{{ inputs.bucket }}"
          AWS_ACCESS_KEY_ID: "{{ secret('AWS_ACCESS_KEY_ID') }}"
          AWS_SECRET_ACCESS_KEY: "{{ secret('AWS_SECRET_ACCESS_KEY') }}"
          AWS_DEFAULT_REGION: "{{ inputs.region }}"
        outputFiles:
          - "*.txt"

      - id: parse_tf_output
        type: io.kestra.plugin.scripts.python.Script
        containerImage: ghcr.io/kestra-io/kestrapy:latest
        inputFiles:
          terraform.txt: "{{ outputs.tf.outputFiles['output.txt'] }}"
        taskRunner:
          type: io.kestra.plugin.scripts.runner.docker.Docker
        script: |
          from kestra import Kestra

          outputs = {}
          with open("terraform.txt", "r") as file:
              print(file)
              for line in file:
                  key, value = line.strip().split(" = ")
                  outputs[key] = value.strip('"')

          Kestra.outputs(outputs)

  - id: parallel_ecs_fargate_tasks
    type: io.kestra.plugin.core.flow.Parallel
    tasks:
      - id: run_python_1
        type: io.kestra.plugin.scripts.python.Commands
        commands:
          - pip show kestra

      - id: run_python_2
        type: io.kestra.plugin.scripts.python.Commands
        commands:
          - python {{ workingDir }}/script.py

      - id: run_python_3
        type: io.kestra.plugin.scripts.python.Commands
        commands:
          - python {{ workingDir }}/demo.py

      - id: run_python_4
        type: io.kestra.plugin.scripts.python.Commands
        commands:
          - python {{ workingDir }}/example.py

  - id: notification
    type: io.kestra.plugin.notifications.slack.SlackIncomingWebhook
    url: https://hooks.slack.com/services/HOOK
    payload: |
      {
        "channel": "#flow-test",
        "text": "Process Complete: {{ execution.id }}"
      }
        
pluginDefaults:
  - type: io.kestra.plugin.scripts.python.Commands
    values:
      containerImage: ghcr.io/kestra-io/pydata:latest
      namespaceFiles:
        enabled: true
      taskRunner:
        type: io.kestra.plugin.aws.runner.Batch
        computeEnvironmentArn: "{{ outputs.parse_tf_output.vars.batch_compute_environment_arn }}"
        jobQueueArn: "{{ outputs.parse_tf_output.vars.batch_job_queue_arn }}"
        executionRoleArn: "{{ outputs.parse_tf_output.vars.ecs_task_execution_role_arn }}"
        taskRoleArn: "{{ outputs.parse_tf_output.vars.ecs_task_role_arn }}"
        accessKeyId: "{{ secret('AWS_ACCESS_KEY_ID') }}"
        secretKeyId: "{{ secret('AWS_SECRET_ACCESS_KEY') }}"
        region: "{{ inputs.region }}"
        bucket: "{{ inputs.bucket }}"
